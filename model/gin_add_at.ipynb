{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hr2OuKpCq839"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "from random import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from utils import *\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QmkPZtF6NoAr"
   },
   "outputs": [],
   "source": [
    "data_path = \"data/split_data/mix_data\"\n",
    "data_processed_path = \"data/split_data/mix_data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPBpKDG_NgwF"
   },
   "source": [
    "#Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zIKk0zrkrF5A"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "# GINConv model\n",
    "class GINConvNet(torch.nn.Module):\n",
    "    def __init__(self, n_output=1,num_features_xd=78, num_features_xt=25,\n",
    "                 n_filters=32, embed_dim=128, output_dim=128, dropout=0.2, out_tissue_d=13):\n",
    "\n",
    "        super(GINConvNet, self).__init__()\n",
    "\n",
    "        dim = 32\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.n_output = n_output\n",
    "        # convolution layers\n",
    "        nn1 = Sequential(Linear(num_features_xd, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv3 = GINConv(nn3)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv4 = GINConv(nn4)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv5 = GINConv(nn5)\n",
    "        self.bn5 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.fc1_xd = Linear(dim, output_dim)\n",
    "\n",
    "        # cell line feature\n",
    "        # ge \n",
    "        self.target_ge_cnv_block = Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=n_filters, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(in_channels=n_filters, out_channels=n_filters*2, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(in_channels=n_filters*2, out_channels=n_filters*4, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2944, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # mut\n",
    "        self.target_mut_cnv_block = Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=n_filters, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(in_channels=n_filters, out_channels=n_filters*2, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(in_channels=n_filters*2, out_channels=n_filters*4, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2944, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # meth\n",
    "        self.target_meth_cnv_block = Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=n_filters, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(in_channels=n_filters, out_channels=n_filters*2, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Conv1d(in_channels=n_filters*2, out_channels=n_filters*4, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # synthetic omics data\n",
    "        self.synthetic_omics = nn.Linear(3*output_dim, 256)\n",
    "        \n",
    "        #attension\n",
    "        self.key_xt = nn.Linear(2*output_dim, output_dim)\n",
    "        self.key_drug = nn.Linear(output_dim, output_dim)\n",
    "        \n",
    "        self.at_fc = nn.Linear(3*output_dim, 1)\n",
    "\n",
    "        # combined layers\n",
    "        self.fc1 = nn.Linear(3*output_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.out = nn.Linear(128, n_output)\n",
    "\n",
    "        # activation and regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "#         Batch(c_size_1=[1024], c_size_2=[1024], edge_index_1=[2, 67864], edge_index_2=[2, 68244],\n",
    "#               target=[1024, 735], x_1=[31406, 78], x_1_batch=[31406], x_2=[31559, 78], x_2_batch=[31559], y=[1024])\n",
    "        x_1_batch = data.x_1_batch\n",
    "        x_1, edge_index_1,  = data.x_1, data.edge_index_1\n",
    "        x_2_batch = data.x_2_batch\n",
    "        x_2, edge_index_2,  = data.x_2, data.edge_index_2\n",
    "\n",
    "#         drug 1\n",
    "        x_1 = F.relu(self.conv1(x_1, edge_index_1))\n",
    "        x_1 = self.bn1(x_1)\n",
    "        x_1 = F.relu(self.conv2(x_1, edge_index_1))\n",
    "        x_1 = self.bn2(x_1)\n",
    "        x_1 = F.relu(self.conv3(x_1, edge_index_1))\n",
    "        x_1 = self.bn3(x_1)\n",
    "        x_1 = F.relu(self.conv4(x_1, edge_index_1))\n",
    "        x_1 = self.bn4(x_1)\n",
    "        x_1 = F.relu(self.conv5(x_1, edge_index_1))\n",
    "        x_1 = self.bn5(x_1)\n",
    "        x_1 = global_add_pool(x_1, x_1_batch)\n",
    "        x_1 = F.relu(self.fc1_xd(x_1))\n",
    "        x_1 = F.dropout(x_1, p=0.2, training=self.training)\n",
    "#         drug 2\n",
    "        x_2 = F.relu(self.conv1(x_2, edge_index_2))\n",
    "        x_2 = self.bn1(x_2)\n",
    "        x_2 = F.relu(self.conv2(x_2, edge_index_2))\n",
    "        x_2 = self.bn2(x_2)\n",
    "        x_2 = F.relu(self.conv3(x_2, edge_index_2))\n",
    "        x_2 = self.bn3(x_2)\n",
    "        x_2 = F.relu(self.conv4(x_2, edge_index_2))\n",
    "        x_2 = self.bn4(x_2)\n",
    "        x_2 = F.relu(self.conv5(x_2, edge_index_2))\n",
    "        x_2 = self.bn5(x_2)\n",
    "        x_2 = global_add_pool(x_2, x_2_batch)\n",
    "        x_2 = F.relu(self.fc1_xd(x_2))\n",
    "        x_2 = F.dropout(x_2, p=0.2, training=self.training)\n",
    "\n",
    "\n",
    "        target_mut = data.target_mut\n",
    "        target_mut = target_mut[:,None,:]\n",
    "        conv_xt_mut = self.target_mut_cnv_block(target_mut)\n",
    "\n",
    "        target_meth = data.target_meth\n",
    "        target_meth = target_meth[:,None,:]\n",
    "        conv_xt_meth = self.target_meth_cnv_block(target_meth)\n",
    "\n",
    "        target_ge = data.target_ge\n",
    "        target_ge = target_ge[:,None,:]\n",
    "        conv_xt_ge = self.target_ge_cnv_block(target_ge)\n",
    "        # 1d conv layers\n",
    "\n",
    "        xt = torch.cat((conv_xt_mut, conv_xt_meth, conv_xt_ge), 1)\n",
    "        xt = self.synthetic_omics(xt)\n",
    "        xt = self.relu(xt)\n",
    "\n",
    "        key_xt = self.key_xt(xt)\n",
    "        key_drug_1 = self.key_drug(x_1)\n",
    "        key_drug_2 = self.key_drug(x_2)\n",
    "#                 print(key_drug_1, key_drug_2)\n",
    "\n",
    "        a_drug_1 = torch.exp(self.leaky_relu(self.at_fc(torch.cat((key_drug_1, key_xt, key_drug_2), 1))))\n",
    "        a_drug_2 = torch.exp(self.leaky_relu(self.at_fc(torch.cat((key_drug_2, key_xt, key_drug_1), 1))))\n",
    "#                 print(a_drug_1, a_drug_2)\n",
    "        total = a_drug_1+a_drug_2\n",
    "        a_drug_1 = torch.div(a_drug_1, total)\n",
    "        a_drug_2 = torch.div(a_drug_2, total)\n",
    "        x_1 = a_drug_1*x_1\n",
    "        x_2 = a_drug_2*x_2\n",
    "        x_drug_combine = x_1 + x_2\n",
    "#                 print(x_drug_combine)\n",
    "\n",
    "        # concat\n",
    "        xc = torch.cat((x_drug_combine, xt), 1)\n",
    "        # add some dense layers\n",
    "        xc = self.fc1(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        xc = self.fc2(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        out = self.out(xc)\n",
    "\n",
    "        return out, a_drug_1, a_drug_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jqz2LGdQuRQ_"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval, critation):\n",
    "    print('Training on {} samples...'.format(len(train_loader.dataset)))\n",
    "    model.train()\n",
    "#     loss_fn = nn.MSELoss()\n",
    "    avg_loss = []\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, x_1, x_2 = model(data)\n",
    "        loss = critation(output, data.y.view(-1, 1).float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss.append(loss.item())\n",
    "        text = 'Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n",
    "                                                                        batch_idx * len(data.x_1),\n",
    "                                                                        len(train_loader.dataset),\n",
    "                                                                        100. * batch_idx / len(train_loader),\n",
    "                                                                        loss.item())\n",
    "\n",
    "#         loop.set_description(text)\n",
    "#         loop.refresh() # to show immediately the update\n",
    "    return sum(avg_loss)/len(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2Iqc09aCuZKQ"
   },
   "outputs": [],
   "source": [
    "def predicting(model, device, loader, ats=False):\n",
    "    model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    if ats:\n",
    "        x_1_predicted = torch.Tensor()\n",
    "        x_2_predicted = torch.Tensor()\n",
    "        print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                data = data.to(device)\n",
    "                output, x_1, x_2 = model(data)\n",
    "                total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
    "                total_labels = torch.cat((total_labels, data.y.view(-1, 1).cpu()), 0)\n",
    "                x_1_predicted = torch.cat((x_1_predicted, x_1.cpu()), 0)\n",
    "                x_2_predicted = torch.cat((x_2_predicted, x_2.cpu()), 0)\n",
    "        return total_labels.numpy().flatten(),total_preds.numpy().flatten(), x_1_predicted, x_2_predicted\n",
    "    else:\n",
    "        print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                data = data.to(device)\n",
    "                output, x_1, x_2 = model(data)\n",
    "                total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
    "                total_labels = torch.cat((total_labels, data.y.view(-1, 1).cpu()), 0)\n",
    "        return total_labels.numpy().flatten(),total_preds.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6Vn8jKcosUEA"
   },
   "outputs": [],
   "source": [
    "def draw(list_, label, y_label, title):\n",
    "    plt.figure()\n",
    "    plt.plot(list_, label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    # save image\n",
    "    plt.savefig(title+\".png\")  # should before show method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rth4mZ0BN4bn"
   },
   "source": [
    "#Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8qktZ2NoN3nN"
   },
   "outputs": [],
   "source": [
    "model_st = \"GINConvNet\"\n",
    "dataset = 'GDSC'\n",
    "train_batch = 1024\n",
    "val_batch = 1024\n",
    "test_batch = 1024\n",
    "log_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413434,
     "status": "ok",
     "timestamp": 1620975636023,
     "user": {
      "displayName": "Hoa D. Vu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi5xuU4jP5haCTK9aB8EdlS9KLrsyHO0J5s60I0xg=s64",
      "userId": "01639392045271123699"
     },
     "user_tz": -420
    },
    "id": "VNOa4SEM-bL4",
    "outputId": "27d073bf-a428-4530-bf5f-094f5221f473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running on  GINConvNet_GDSC\n",
      "Pre-processed data found: data/split_data/mix_data/processed/GDSC_train_dc.pt, loading ...\n",
      "Pre-processed data found: data/split_data/mix_data/processed/GDSC_val_dc.pt, loading ...\n",
      "Pre-processed data found: data/split_data/mix_data/processed/GDSC_test_dc.pt, loading ...\n"
     ]
    }
   ],
   "source": [
    "print('\\nrunning on ', model_st + '_' + dataset )\n",
    "train_data = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'train_dc')\n",
    "val_data = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'val_dc')\n",
    "test_data = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'test_dc')\n",
    "\n",
    "# val_mix_dc = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'mix_val')\n",
    "# val_blind_cell = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_cell_val')\n",
    "# val_blind_1_drug = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_1_drug_val')\n",
    "# val_blind_1_drug_cell = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_1_drug_cell_val')\n",
    "# val_blind_2_drug = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_2_drug_val')\n",
    "# val_blind_all = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_all_val')\n",
    "\n",
    "\n",
    "# test_mix_dc = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'mix_test')\n",
    "# test_blind_cell = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_cell_test')\n",
    "# test_blind_1_drug = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_1_drug_test')\n",
    "# test_blind_1_drug_cell = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_1_drug_cell_test')\n",
    "# test_blind_2_drug = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_2_drug_test')\n",
    "# test_blind_all = TestbedDataset(root=data_path, dataset=dataset+\"_\"+'blind_all_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413432,
     "status": "ok",
     "timestamp": 1620975636028,
     "user": {
      "displayName": "Hoa D. Vu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi5xuU4jP5haCTK9aB8EdlS9KLrsyHO0J5s60I0xg=s64",
      "userId": "01639392045271123699"
     },
     "user_tz": -420
    },
    "id": "K1NjTIkT-TEo",
    "outputId": "1b4ce363-7a2d-4f43-98ad-33bf1e77a8c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU/GPU:  True\n"
     ]
    }
   ],
   "source": [
    "# make data PyTorch\n",
    "# mini-batch processing ready\n",
    "train_loader = DataLoader(train_data, batch_size=train_batch, shuffle=True, follow_batch=['x_1', 'x_2'])\n",
    "val_loader = DataLoader(val_data, batch_size=val_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "\n",
    "# val_mix_dc_loader = DataLoader(val_mix_dc, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# val_blind_cell_loader = DataLoader(val_blind_cell, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# val_blind_1_drug_loader = DataLoader(val_blind_1_drug, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# val_blind_1_drug_cell_loader = DataLoader(val_blind_1_drug_cell, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# val_blind_2_drug_loader = DataLoader(val_blind_2_drug, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# val_blind_all_loader = DataLoader(val_blind_all, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "\n",
    "# test_mix_dc_loader = DataLoader(test_mix_dc, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# test_blind_cell_loader = DataLoader(test_blind_cell, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# test_blind_1_drug_loader = DataLoader(test_blind_1_drug, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# test_blind_1_drug_cell_loader = DataLoader(test_blind_1_drug_cell, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# test_blind_2_drug_loader = DataLoader(test_blind_2_drug, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "# test_blind_all_loader = DataLoader(test_blind_all, batch_size=test_batch, shuffle=False, follow_batch=['x_1', 'x_2'])\n",
    "\n",
    "print(\"CPU/GPU: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMQ9mAaHN7Rs"
   },
   "source": [
    "#Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDi7b574PBzl"
   },
   "source": [
    "##Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413425,
     "status": "ok",
     "timestamp": 1620975636029,
     "user": {
      "displayName": "Hoa D. Vu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi5xuU4jP5haCTK9aB8EdlS9KLrsyHO0J5s60I0xg=s64",
      "userId": "01639392045271123699"
     },
     "user_tz": -420
    },
    "id": "eChUZinTPIsl",
    "outputId": "b7d5795d-5cac-4444-ab87-4d6598c3f618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "modeling = GINConvNet\n",
    "model = modeling().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-fGib0aPW5H"
   },
   "source": [
    "##Define paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413417,
     "status": "ok",
     "timestamp": 1620975636029,
     "user": {
      "displayName": "Hoa D. Vu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi5xuU4jP5haCTK9aB8EdlS9KLrsyHO0J5s60I0xg=s64",
      "userId": "01639392045271123699"
     },
     "user_tz": -420
    },
    "id": "KvyarP1DJP4U",
    "outputId": "6f3012c7-6ca3-4a4c-e216-f81e20a5dc6f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epochs:  300\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "num_epoch = 300\n",
    "best_ret_test = None\n",
    "print('Learning rate: ', lr)\n",
    "print('Epochs: ', num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "C08SzL4WPWXE"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_pearsons = []\n",
    "\n",
    "val_mix_dc_losses = []\n",
    "val_blind_cell_losses = []\n",
    "val_blind_1_drug_losses = []\n",
    "val_blind_1_drug_cell_losses = []\n",
    "val_blind_2_drug_losses = []\n",
    "val_blind_all_losses = []\n",
    "\n",
    "val_mix_dc_pearsons = []\n",
    "val_blind_cell_pearsons = []\n",
    "val_blind_1_drug_pearsons = []\n",
    "val_blind_1_drug_cell_pearsons = []\n",
    "val_blind_2_drug_pearsons = []\n",
    "val_blind_all_pearsons = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VniJdvO-PJ89"
   },
   "source": [
    "##Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BQesXT4SbORG"
   },
   "outputs": [],
   "source": [
    "model_names = ['GIN', \"GAT\", \"GCN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "apGwAOJw5E50"
   },
   "outputs": [],
   "source": [
    "save_path = \"model/save_model/\" + \"GIN_ADD_AT/temp/mix_data\" + \"/\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "best_mse = 1000\n",
    "best_pearson = 1\n",
    "best_epoch = -1\n",
    "\n",
    "best_val_losses = 10000\n",
    "best_val_mix_dc_losses = 10000\n",
    "best_val_blind_cell_losses = 10000\n",
    "best_val_blind_1_drug_losses = 10000\n",
    "best_val_blind_1_drug_cell_losses = 10000\n",
    "best_val_blind_2_drug_losses = 10000\n",
    "best_val_blind_all_losses = 10000\n",
    "\n",
    "\n",
    "ret_test_save = [1,1]\n",
    "ret_test_mix_dc_save = [1,1] \n",
    "ret_test_blind_cell_save = [1,1]\n",
    "ret_test_blind_1_drug_save = [1,1]\n",
    "ret_test_blind_1_drug_cell_save = [1,1]\n",
    "ret_test_blind_2_drug_save = [1,1]\n",
    "ret_test_blind_all_save = [1,1]\n",
    "\n",
    "\n",
    "model_file_name = save_path + 'best_model' + '.model'\n",
    "current_file_model = save_path + 'current_model_' + '.model'\n",
    "model_all_file_name = save_path + 'model_all' + '.model'\n",
    "model_mix_file_name = save_path + 'model_mix' + '.model'\n",
    "model_blind_cell_file_name = save_path + 'model_blind_cell' + '.model'\n",
    "model_blind_1_drug_file_name = save_path + 'model_blind_1_drug' + '.model'\n",
    "model_blind_1_drug_cell_file_name = save_path + 'model_blind_1_drug_cell' + '.model'\n",
    "model_blind_2_drug_file_name = save_path + 'model_blind_2_drug' + '.model'\n",
    "model_blind_all_file_name = save_path + 'model_blind_all' + '.model'\n",
    "\n",
    "result_file_name = save_path + 'result_' + model_st + '_' + dataset +  '.csv'\n",
    "\n",
    "loss_fig_name = save_path + 'model_' + model_st + '_' + dataset + '_loss'\n",
    "pearson_fig_name = save_path + 'model_' + model_st + '_' + dataset + '_pearson'\n",
    "\n",
    "loss_fig_name_mix_dc = save_path + 'model_' + model_st + '_' + dataset + '_loss_mix_dc'\n",
    "pearson_fig_name_mix_dc = save_path + 'model_' + model_st + '_' + dataset + '_pearson_mix_dc'\n",
    "\n",
    "loss_fig_name_blind_cell = save_path + 'model_' + model_st + '_' + dataset + '_loss_blind_cell'\n",
    "pearson_fig_name_blind_cell = save_path + 'model_' + model_st + '_' + dataset + '_pearson_blind_cell'\n",
    "\n",
    "loss_fig_name_blind_1_drug = save_path + 'model_' + model_st + '_' + dataset + '_loss_blind_1_drug'\n",
    "pearson_fig_name_blind_1_drug = save_path + 'model_' + model_st + '_' + dataset + '_pearson_blind_1_drug'\n",
    "\n",
    "loss_fig_name_blind_1_drug_cell = save_path + 'model_' + model_st + '_' + dataset + '_loss_blind_1_drug_cell'\n",
    "pearson_fig_name_blind_1_drug_cell = save_path + 'model_' + model_st + '_' + dataset + '_pearson_blind_1_drug_cell'\n",
    "\n",
    "loss_fig_name_blind_2_drug = save_path + 'model_' + model_st + '_' + dataset + '_loss_blind_2_drug'\n",
    "pearson_fig_name_blind_2_drug = save_path + 'model_' + model_st + '_' + dataset + '_pearson_blind_2_drug'\n",
    "\n",
    "loss_fig_name_blind_all = save_path + 'model_' + model_st + '_' + dataset + '_loss_blind_all'\n",
    "pearson_fig_name_blind_all = save_path + 'model_' + model_st + '_' + dataset + '_pearson_blind_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mix_dc_losses = []\n",
    "val_blind_cell_losses = []\n",
    "val_blind_1_drug_losses = []\n",
    "val_blind_1_drug_cell_losses = []\n",
    "val_blind_2_drug_losses = []\n",
    "val_blind_all_losses = []\n",
    "\n",
    "val_mix_dc_pearsons = []\n",
    "val_blind_cell_pearsons = []\n",
    "val_blind_1_drug_pearsons = []\n",
    "val_blind_1_drug_cell_pearsons = []\n",
    "val_blind_2_drug_pearsons = []\n",
    "val_blind_all_pearsons = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXRUptKSbb48"
   },
   "source": [
    "\n",
    "#Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ouFIl9iPbg4M"
   },
   "outputs": [],
   "source": [
    "# #load model\n",
    "# if os.path.exists(current_file_model):\n",
    "#   model.load_state_dict(torch.load(current_file_model))\n",
    "#   with open(save_path+ \"log.pickle\", \"rb\") as f:\n",
    "#     log = pickle.load(f)\n",
    "# #   train_losses, val_losses,\\\n",
    "# #   val_mix_dc_losses, val_blind_cell_losses,\\\n",
    "# #   val_blind_1_drug_losses, val_blind_1_drug_cell_losses,\\\n",
    "# #   val_blind_2_drug_losses, val_blind_all_losses,\\\n",
    "# #   val_mix_dc_pearsons, val_blind_cell_pearsons,\\\n",
    "# #   val_blind_1_drug_pearsons, val_blind_1_drug_cell_pearsons,\\\n",
    "# #   val_blind_2_drug_pearsons, val_blind_all_pearsons\\\n",
    "# #   = log\n",
    "#   best_mse = min(val_losses)\n",
    "#   best_pearson = 1\n",
    "#   best_epoch = -1\n",
    "#   print(\"load previous model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ret(G, P):\n",
    "    return [rmse(G,P),mse(G,P),pearson(G,P),spearman(G,P)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EH8vCq03cXSG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training on 17666 samples...\n",
      "Training on 17666 samples...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.44 GiB (GPU 0; 15.74 GiB total capacity; 9.05 GiB already allocated; 1.06 GiB free; 9.10 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0e01d7de6bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {} | Training on {} samples...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#VAL:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5c7fcaf4d81f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval, critation)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/client/user1/anaconda3/envs/hoavd/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8cb8b946b021>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mtarget_ge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_ge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mtarget_ge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mconv_xt_ge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_ge_cnv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;31m# 1d conv layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/client/user1/anaconda3/envs/hoavd/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/client/user1/anaconda3/envs/hoavd/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/client/user1/anaconda3/envs/hoavd/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/client/user1/anaconda3/envs/hoavd/lib/python3.9/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/client/user1/anaconda3/envs/hoavd/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.44 GiB (GPU 0; 15.74 GiB total capacity; 9.05 GiB already allocated; 1.06 GiB free; 9.10 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output \n",
    "loss_fn = nn.MSELoss()\n",
    "for epoch in range(num_epoch):\n",
    "    print('Epoch {} | Training on {} samples...'.format(epoch, len(train_loader.dataset)))\n",
    "    avg_loss = []    \n",
    "    train_loss = train(model, device, train_loader, optimizer, epoch+1, log_interval, loss_fn)\n",
    "    #VAL:\n",
    "    G,P = predicting(model, device, val_loader)\n",
    "#     G_mix_dc, P_mix_dc = predicting(model, device, val_mix_dc_loader)\n",
    "#     G_blind_cell, P_blind_cell = predicting(model, device, val_blind_cell_loader)\n",
    "#     G_blind_1_drug, P_blind_1_drug = predicting(model, device, val_blind_1_drug_loader)\n",
    "#     G_blind_1_drug_cell, P_blind_1_drug_cell = predicting(model, device, val_blind_1_drug_cell_loader)\n",
    "#     G_blind_2_drug, P_blind_2_drug = predicting(model, device, val_blind_2_drug_loader)\n",
    "#     G_blind_all, P_blind_all = predicting(model, device, val_blind_all_loader)\n",
    "    \n",
    "\n",
    "    ret = return_ret(G, P)\n",
    "#     ret_mix_dc = return_ret(G_mix_dc, P_mix_dc)\n",
    "#     ret_blind_cell = return_ret(G_blind_cell, P_blind_cell)\n",
    "#     ret_blind_1_drug = return_ret(G_blind_1_drug, P_blind_1_drug)\n",
    "#     ret_blind_1_drug_cell = return_ret(G_blind_1_drug_cell, P_blind_1_drug_cell)\n",
    "#     ret_blind_2_drug = return_ret(G_blind_2_drug, P_blind_2_drug)\n",
    "#     ret_blind_all = return_ret(G_blind_all, P_blind_all)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(ret[1])\n",
    "    val_pearsons.append(ret[2])\n",
    "\n",
    "#     val_mix_dc_losses.append(ret_mix_dc[1])\n",
    "#     val_blind_cell_losses.append(ret_blind_cell[1])\n",
    "#     val_blind_1_drug_losses.append(ret_blind_1_drug[1])\n",
    "#     val_blind_1_drug_cell_losses.append(ret_blind_1_drug_cell[1])\n",
    "#     val_blind_2_drug_losses.append(ret_blind_2_drug[1])\n",
    "#     val_blind_all_losses.append(ret_blind_all[1])\n",
    "    \n",
    "\n",
    "#     val_mix_dc_pearsons.append(ret_mix_dc[2])\n",
    "#     val_blind_cell_pearsons.append(ret_blind_cell[2])\n",
    "#     val_blind_1_drug_pearsons.append(ret_blind_1_drug[2])\n",
    "#     val_blind_1_drug_cell_pearsons.append(ret_blind_1_drug_cell[2])\n",
    "#     val_blind_2_drug_pearsons.append(ret_blind_2_drug[2])\n",
    "#     val_blind_all_pearsons.append(ret_blind_all[2])\n",
    "    \n",
    "    if ret[1]<best_val_losses:\n",
    "        best_val_losses = ret[1]\n",
    "        G_test,P_test = predicting(model, device, test_loader)\n",
    "        ret_test_save = return_ret(G_test, P_test)\n",
    "        print(\"RMSE all test improved\")\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "#     if ret_mix_dc[1]<best_val_mix_dc_losses:\n",
    "#         best_val_mix_dc_losses = ret_mix_dc[1]\n",
    "#         G_mix_dc_test, P_mix_dc_test = predicting(model, device, test_mix_dc_loader)\n",
    "#         ret_test_mix_dc_save = return_ret(G_mix_dc_test, P_mix_dc_test)\n",
    "#         print(\"RMSE mix test improved\")\n",
    "#     if ret_blind_cell[1]<best_val_blind_cell_losses:\n",
    "#         best_val_blind_cell_losses = ret_blind_cell[1]\n",
    "#         G_blind_cell_test, P_blind_cell_test = predicting(model, device, test_blind_cell_loader)\n",
    "#         ret_test_blind_cell_save = return_ret(G_blind_cell_test, P_blind_cell_test)\n",
    "#         print(\"RMSE blind cell test improved\")\n",
    "#     if ret_blind_1_drug[1]<best_val_blind_1_drug_losses:\n",
    "#         best_val_blind_1_drug_losses = ret_blind_1_drug[1]\n",
    "#         G_blind_1_drug_test, P_blind_1_drug_test = predicting(model, device, test_blind_1_drug_loader)\n",
    "#         ret_test_blind_1_drug_save = return_ret(G_blind_1_drug_test, P_blind_1_drug_test)\n",
    "#         print(\"RMSE blind 1 drug improved\")\n",
    "#     if ret_blind_1_drug_cell[1]<best_val_blind_1_drug_cell_losses:\n",
    "#         best_val_blind_1_drug_cell_losses = ret_blind_1_drug_cell[1]\n",
    "#         G_blind_1_drug_cell_test, P_blind_1_drug_cell_test = predicting(model, device, test_blind_1_drug_cell_loader)\n",
    "#         ret_test_blind_1_drug_cell_save = return_ret(G_blind_1_drug_cell_test, P_blind_1_drug_cell_test)\n",
    "#         print(\"RMSE blind 1 drug cell improved\")\n",
    "#     if ret_blind_2_drug[1]<best_val_blind_2_drug_losses:\n",
    "#         best_val_blind_2_drug_losses = ret_blind_2_drug[1]\n",
    "#         G_blind_2_drug_test, P_blind_2_drug_test = predicting(model, device, test_blind_2_drug_loader)\n",
    "#         ret_test_blind_2_drug_save = return_ret(G_blind_2_drug_test, P_blind_2_drug_test)\n",
    "#         print(\"RMSE blind 2 drug improved\")\n",
    "#     if ret_blind_all[1]<best_val_blind_all_losses:\n",
    "#         best_val_blind_all_losses = ret_blind_all[1]\n",
    "#         G_blind_all_test, P_blind_all_test = predicting(model, device, test_blind_all_loader)\n",
    "#         ret_test_blind_all_save = return_ret(G_blind_all_test, P_blind_all_test)\n",
    "#         print(\"RMSE blind all improved\")\n",
    "        \n",
    "    \n",
    "    with open(result_file_name,'w') as f:\n",
    "        f.write('ret_test: '+','.join(map(str,ret_test_save)) +\"\\n\")\n",
    "#         f.write('ret_mix_dc: '+','.join(map(str,ret_test_mix_dc_save)) +\"\\n\")\n",
    "#         f.write('ret_blind_cell: '+','.join(map(str,ret_test_blind_cell_save)) +\"\\n\")\n",
    "#         f.write('ret_blind_1_drug: '+','.join(map(str,ret_test_blind_1_drug_save)) +\"\\n\")\n",
    "#         f.write('ret_blind_1_drug_cell: '+','.join(map(str,ret_test_blind_1_drug_cell_save)) +\"\\n\")\n",
    "#         f.write('ret_blind_2_drug: '+','.join(map(str,ret_test_blind_2_drug_save)) +\"\\n\")\n",
    "#         f.write('ret_blind_all: '+','.join(map(str,ret_test_blind_all_save)) +\"\\n\")\n",
    "        \n",
    "    draw_loss(train_losses, val_losses, loss_fig_name)\n",
    "    draw_pearson(val_pearsons, pearson_fig_name)\n",
    "\n",
    "#     draw_loss(train_losses, val_mix_dc_losses, loss_fig_name_mix_dc)\n",
    "#     draw_pearson(val_mix_dc_pearsons, pearson_fig_name_mix_dc)\n",
    "\n",
    "#     draw_loss(train_losses, val_blind_cell_losses, loss_fig_name_blind_cell)\n",
    "#     draw_pearson(val_blind_cell_pearsons, pearson_fig_name_blind_cell)\n",
    "\n",
    "#     draw_loss(train_losses, val_blind_1_drug_losses, loss_fig_name_blind_1_drug)\n",
    "#     draw_pearson(val_blind_1_drug_pearsons, pearson_fig_name_blind_1_drug)\n",
    "    \n",
    "#     draw_loss(train_losses, val_blind_1_drug_cell_losses, loss_fig_name_blind_1_drug_cell)\n",
    "#     draw_pearson(val_blind_1_drug_cell_pearsons, pearson_fig_name_blind_1_drug_cell)\n",
    "    \n",
    "#     draw_loss(train_losses, val_blind_2_drug_losses, loss_fig_name_blind_2_drug)\n",
    "#     draw_pearson(val_blind_2_drug_pearsons, pearson_fig_name_blind_2_drug)\n",
    "    \n",
    "#     draw_loss(train_losses, val_blind_all_losses, loss_fig_name_blind_all)\n",
    "#     draw_pearson(val_blind_all_pearsons, pearson_fig_name_blind_all)\n",
    "\n",
    "    torch.save(model.state_dict(), current_file_model)\n",
    "    log = [\n",
    "          train_losses, val_losses,\\\n",
    "#           val_mix_dc_losses, val_blind_cell_losses,\\\n",
    "#           val_blind_1_drug_losses, val_blind_1_drug_cell_losses,\\\n",
    "#           val_blind_2_drug_losses, val_blind_all_losses,\\\n",
    "#           val_mix_dc_pearsons, val_blind_cell_pearsons,\\\n",
    "#           val_blind_1_drug_pearsons, val_blind_1_drug_cell_pearsons,\\\n",
    "#           val_blind_2_drug_pearsons, val_blind_all_pearsons\n",
    "          ]\n",
    "\n",
    "    with open(save_path+ \"/log.pickle\", \"wb\") as f:\n",
    "      pickle.dump(log, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_path = \"data/split_data/mix_data/\"\n",
    "train_dc = pd.read_csv(data_split_path+\"train_dc.csv\")\n",
    "test_dc = pd.read_csv(data_split_path+\"test_dc.csv\")\n",
    "val_dc = pd.read_csv(data_split_path+\"val_dc.csv\")\n",
    "\n",
    "# mix_val = pd.read_csv(data_split_path+\"mix_val.csv\")\n",
    "# mix_test = pd.read_csv(data_split_path+\"mix_test.csv\")\n",
    "\n",
    "# blind_cell_val = pd.read_csv(data_split_path+\"blind_cell_val.csv\")\n",
    "# blind_cell_test = pd.read_csv(data_split_path+\"blind_cell_test.csv\")\n",
    "\n",
    "# blind_1_drug_val = pd.read_csv(data_split_path+\"blind_1_drug_val.csv\")\n",
    "# blind_1_drug_test = pd.read_csv(data_split_path+\"blind_1_drug_test.csv\")\n",
    "\n",
    "# blind_1_drug_cell_val = pd.read_csv(data_split_path+\"blind_1_drug_cell_val.csv\")\n",
    "# blind_1_drug_cell_test = pd.read_csv(data_split_path+\"blind_1_drug_cell_test.csv\")\n",
    "\n",
    "# blind_2_drug_val = pd.read_csv(data_split_path+\"blind_2_drug_val.csv\")\n",
    "# blind_2_drug_test = pd.read_csv(data_split_path+\"blind_2_drug_test.csv\")\n",
    "\n",
    "# blind_all_val = pd.read_csv(data_split_path+\"blind_all_val.csv\")\n",
    "# blind_all_test = pd.read_csv(data_split_path+\"blind_all_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {\n",
    "    \"test\": (predicting(model, device, test_loader, ats=True), test_dc),\n",
    "#     \"mix\": (G_mix_dc_test, P_mix_dc_test, mix_test),\n",
    "#     \"blind_cell\": (G_blind_cell_test, P_blind_cell_test, blind_cell_test),\n",
    "#     \"blind_1_drug\": (G_blind_1_drug_test, P_blind_1_drug_test, blind_1_drug_test),\n",
    "#     \"blind_1_drug_cell\": (G_blind_1_drug_cell_test, P_blind_1_drug_cell_test, blind_1_drug_cell_test),\n",
    "#     \"blind_2_drug\": (G_blind_2_drug_test, P_blind_2_drug_test, blind_2_drug_test),\n",
    "#     \"blind_all\": (G_blind_all_test, P_blind_all_test, blind_all_test)   \n",
    "}\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "if os.path.exists(current_file_model):\n",
    "    model.load_state_dict(torch.load(current_file_model))\n",
    "\n",
    "def r2_rmse( g ):\n",
    "    r2 =  mean_squared_error( g['synergy'], g['predict'] )\n",
    "    count = len(g['synergy'])\n",
    "    rmse = np.sqrt( mean_squared_error( g['synergy'], g['predict'] ) )\n",
    "    return pd.Series( dict(  r2 = r2, rmse = rmse, count = count ) )\n",
    "\n",
    "def get_top_data(r, df, top=10):\n",
    "    G, P, x_1_ats, x_2_ats = r\n",
    "    x_1_ats = np.array(x_1_ats)\n",
    "    x_2_ats = np.array(x_2_ats)\n",
    "    top = top*2\n",
    "    abs_error = np.abs(G-P)\n",
    "    index_top = abs_error.argsort()[:]\n",
    "    values = abs_error[index_top]\n",
    "    df_top = df.iloc[index_top].copy()\n",
    "    df_top[\"log_synergy\"] = G[index_top]\n",
    "    df_top[\"predict\"] = P[index_top]\n",
    "    df_top[\"abs_error\"] = values\n",
    "    df_top[\"x_1_ats\"] = x_1_ats[index_top]\n",
    "    df_top[\"x_2_ats\"] = x_2_ats[index_top]\n",
    "    return df_top\n",
    "\n",
    "for key, value in tqdm(result_dict.items()):\n",
    "    temp = get_top_data(value[0], value[1])\n",
    "#     top_2_drug = temp.groupby(['Drug1', 'Drug2']).apply( r2_rmse ).reset_index().sort_values(by=['rmse'])\n",
    "#     top_1_drug = temp.groupby(['Drug1']).apply( r2_rmse ).reset_index().sort_values(by=['rmse'])\n",
    "#     top_2_drug.to_csv(save_path+\"save_top/\"+key+\"2_drug\"+\".csv\", index=False)\n",
    "#     top_1_drug.to_csv(save_path+\"save_top/\"+key+\"1_drug\"+\".csv\", index=False)\n",
    "temp.to_csv(save_path+\"detail_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "gin.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "hoavd",
   "language": "python",
   "name": "hoavd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
